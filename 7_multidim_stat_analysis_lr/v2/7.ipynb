{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1e466b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.metrics import r2_score as r2_sklean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514ffeb",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Дана матрица объект-признак X\n",
    "и значения целевой переменной y.\n",
    "\n",
    "Подберите два признака (из четырёх) так, чтобы уровень линейной зависимости целевой переменной от значений этих признаков был максимальным. Другими словами, модель линейной регрессии на этих признаках должна давать наилучший результат. В качестве ответа запишите значение коэффициента детерминации для модели на этих признаках.\n",
    "\n",
    "Ответ: 0.76342462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd77fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[ 1.22401313,  2.30868478,  3.03636353,  2.69287214],\n",
    "     [-0.18757272,  1.30337355,  5.12093014,  3.46363202],\n",
    "     [-0.81094525,  1.82463398,  5.79686488,  1.86159445],\n",
    "     [ 0.75129018,  2.67392052,  3.65529809,  1.66746094],\n",
    "     [ 0.00972362,  1.97367255,  2.50594319,  1.69755173],\n",
    "     [-0.62972637,  0.77750764,  2.84124027,  4.54410559],\n",
    "     [ 2.29536229,  1.81206697,  1.95026215,  1.51874636],\n",
    "     [ 0.0920418 ,  2.26971361,  7.47708735,  2.61081203],\n",
    "     [ 2.39252799,  3.17563985,  3.61420599,  5.10773362],\n",
    "     [ 0.54983815,  2.87988651,  1.65752765,  1.59635987]]\n",
    "\n",
    "y = [ 9.26193358,  9.700363  ,  8.67214805,  8.74796974,  6.18689108,\n",
    "      7.53312713,  7.57643777, 12.44965478, 14.29010746,  6.68361218]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5c74d",
   "metadata": {},
   "source": [
    "$${\\beta} = \\left( X^\\top X \\right)^{-1} X^\\top Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be06e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 1, 2, 3]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3290af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_num(X) -> int:\n",
    "    if X.shape[0] == 1:\n",
    "        n_features = 1\n",
    "    else:\n",
    "        n_features: int = X.shape[1]\n",
    "    return n_features\n",
    "\n",
    "\n",
    "def lr_predict(X, y) -> list:\n",
    "    \"\"\"Returns linear approximated list of values\"\"\"\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    n_feats = features_num(X)\n",
    "    if n_feats == 1:\n",
    "        b0, b1 = get_lr_coefficients(X, y)\n",
    "        preds: list = b0 + b1 * X\n",
    "    elif n_feats > 1:\n",
    "        b, X = get_lr_coefficients(X, y)\n",
    "        preds = X.dot(b)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_lr_coefficients(X, y) -> (float, float) or list:\n",
    "    \"\"\"Returns linear regression coefficients\"\"\"\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    n_features = features_num(X)\n",
    "            \n",
    "    if n_features == 1: # simple linear regression\n",
    "        b1: float = covariance(X, y, unbiased=True)[0, 1] / variance(X)  \n",
    "        b0: float = mean(y) - b1 * mean(X)\n",
    "        return b0, b1\n",
    "    \n",
    "    elif n_features > 1: # least squares method \n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((ones, X))\n",
    "        XTX = X.T.dot(X)\n",
    "        XTX_inv = np.linalg.inv(XTX)\n",
    "        b = XTX_inv.dot(X.T).dot(y)\n",
    "        return b, X\n",
    "    \n",
    "def covariance(X: list, y: list, unbiased: bool = True) -> float:\n",
    "    \"\"\"Выборочная ковариация\"\"\"\n",
    "    mean_X: float = mean(X)\n",
    "    mean_y: float = mean(y)\n",
    "    l: list = list(map(lambda x, y: (x - mean_X) * (y - mean_y), X, y))\n",
    "    return sum(l) / (len(l) - int(unbiased))\n",
    "\n",
    "\n",
    "def variance(X: list, unbiased: bool = True) -> float:\n",
    "    mean_X: float = mean(X)\n",
    "    deviations: list = [(x - mean_X)**2 for x in X]\n",
    "    return sum(deviations) / (len(X) - int(unbiased))\n",
    "\n",
    "\n",
    "def mean(l: list) -> float:\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce0cb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"Коэффициент детерминации\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    true_mean = mean(y_true)\n",
    "    err1 = ((y_true - y_pred)**2).sum()\n",
    "    err2 = ((y_true - true_mean)**2).sum()\n",
    "    return 1 - err1 / err2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1fe6053b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[0;32m----> 2\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mlr_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m r2_score(y, preds)\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mlr_predict\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m n_feats \u001b[38;5;241m=\u001b[39m features_num(X)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_feats \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     b0, b1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_lr_coefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     preds: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m b0 \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;241m*\u001b[39m X\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_feats \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mget_lr_coefficients\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m n_features \u001b[38;5;241m=\u001b[39m features_num(X)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m# simple linear regression\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     b1: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcovariance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munbiased\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m variance(X)  \n\u001b[1;32m     29\u001b[0m     b0: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m mean(y) \u001b[38;5;241m-\u001b[39m b1 \u001b[38;5;241m*\u001b[39m mean(X)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m b0, b1\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "preds = lr_predict(X[:, 3:5], y)\n",
    "\n",
    "r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e29b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8306451612903226, 0.8306451612903226)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = [1, 2, 3, 4, 4, 5, 6]; y2 = [2, 2, 3, 4, 4, 6, 7]\n",
    "r2_score(y_true=y1, y_pred=y2), r2_sklean(y_true=y1, y_pred=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be957067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.9523809523809526, 2.9523809523809526)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(y1, ddof=1), variance(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd3311b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.95238095, 3.16666667],\n",
       "        [3.16666667, 3.66666667]]),\n",
       " 3.1666666666666665)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(y1, y2, ddof=1), covariance(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b34bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.22401313, -0.18757272, -0.81094525,  0.75129018,  0.00972362,\n",
       "       -0.62972637,  2.29536229,  0.0920418 ,  2.39252799,  0.54983815])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c895b23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_lr_coefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36mget_lr_coefficients\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"Returns linear regression coefficients\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m X, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m---> 24\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[43mnum_features\u001b[49m(X)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m# simple linear regression\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     b1: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m covariance(X, y, unbiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m variance(X)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_features' is not defined"
     ]
    }
   ],
   "source": [
    "get_lr_coefficients(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f488c",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Является ли значимым уравнение регрессии, полученное в предыдущей задаче? В качестве ответа запишите 1, если является, и 0 иначе.\n",
    "\n",
    "Ответ: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa9b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "381e3f15",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "\n",
    "Для проведения A/B-тестирования сайта интернет-магазина были получены следующие данные: страница A была посещена 2509 раз, из них 77 закончились совершением покупки, страница B была посещена 1465 раз, 60 из них закончились совершением покупки. Является ли значимым отличие конверсии на страницах A и B? В качестве ответа запишите 1, если является, и 0 иначе.\n",
    "\n",
    "_Подсказка_. Реализуйте двухвыборочный t-тест. В качестве выборок здесь можно взять наборы меток совершения покупки (0 или 1) каждым посетителем.\n",
    "\n",
    "Ответ: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0538252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
